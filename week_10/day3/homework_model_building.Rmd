---
title: 'Manual model development'
output:
  html_document:
    toc: true
    toc_float: true
    number_sections: true
    df_print: paged
    css: ../../../styles.css
  pdf_document: default
---


# MVP

You are given a set of data on housing sale prices for the last few years in King County (near Seattle) between May 2014 and May 2015.

<br>
<div class="emphasis">
We want you to build an **explanatory model** for the `price` of housing in King County, i.e. an interpretable model in which the included variables are statistically justifiable.

The variable definitions are:

`id` - Unique ID for each home sold  
`date` - Date of the home sale  
`price` - Price of each home sold  
`bedrooms` - Number of bedrooms  
`bathrooms` - Number of bathrooms, where .5 accounts for a room with a toilet but no shower  
`sqft_living` - Square footage of the apartments interior living space  
`sqft_lot` - Square footage of the land space  
`floors` - Number of floors  
`waterfront` - A dummy variable for whether the apartment was overlooking the waterfront or not  
`view` - An index from 0 to 4 of how good the view of the property was  
`condition` - An index from 1 to 5 on the condition of the apartment  
`grade` - An index from 1 to 13, where 1-3 falls short of building construction and design, 7 has an average level of construction and design, and 11-13 have a high quality level of construction and design  
`sqft_above` - The square footage of the interior housing space that is above ground level  
`sqft_basement` - The square footage of the interior housing space that is below ground level  
`yr_built` - The year the house was initially built  
`yr_renovated` - The year of the houseâ€™s last renovation  
`zipcode` - What zipcode area the house is in  
`lat` - Lattitude  
`long` - Longitude  
`sqft_living15` - The square footage of interior housing living space for the nearest 15 neighbors  
`sqft_lot15` - The square footage of the land lots of the nearest 15 neighbors  
</div>
<br>


# Question 1

Tidy up the data ready for regression:

    * You might like to think about removing some or all of `date`, `id`, `sqft_living15`, `sqft_lot15` and `zipcode` (`lat` and `long` provide a better measure of location in any event).
    * Have a think about how to treat `waterfront`. Should we convert its type?
    * We converted `yr_renovated` into a `renovated` logical variable, indicating whether the property had ever been renovated. You may wish to do the same.
    * Have a think about how to treat `condition` and `grade`? Are they interval or categorical ordinal data types?
```{r}
library(tidyverse)
library(janitor)
library(GGally)
library(modelr)
```


```{r}
houses <- clean_names(read_csv("data/kc_house_data.csv"))

houses_tidy <- houses %>%
  select(-c("id", "date", "sqft_living15", "sqft_lot15", "zipcode")) %>%
  mutate(waterfront = as.logical(waterfront)) %>%
  mutate(renovated = yr_renovated != 0) %>%
  select(-"yr_renovated") %>%
  mutate(condition = as_factor(condition)) %>%
  mutate(grade = as_factor(grade)) %>% 
  mutate(view = as.logical(view))


# removed date as not sure if it can be included in a regression
# removed id as it is not expected to have any explanatory power
# removed sqft_living15 and sqft_loft15 as they are may not be independent of sqft_living and sqft_loft
# removed zipcode as lat and long explain the location more accurately


# kept unaltered as it seems to look like a dummy variable

glimpse(houses_tidy)

# conditional and grade are categorical and ordinal


```


# Question 2

Check for aliased variables using the `alias()` function (this takes in a formula object and a data set). [**Hint** - formula `price ~ .` says "price varying with all predictors", this is a suitable input to `alias()`]. Remove variables that lead to an alias. Check the 'Elements of multiple regression' lesson for a dropdown containing further information on finding aliased variables in a dataset.
```{r}
alias(lm(price ~ ., data = houses_tidy))
```
```{r}
# decided to drop sqft_living, as it seem to be equal to sqft_basement + sqft_above
houses_tidy <- kc_data_trimmed %>% 
  select(-c("sqft_living"))

glimpse(houses_tidy)
```


# Question 3

Systematically build a regression model containing up to **four** main effects (remember, a main effect is just a single predictor with coefficient), testing the regression diagnostics as you go
    * splitting datasets into numeric and non-numeric columns might help `ggpairs()` run in manageable time, although you will need to add either a `price` or `resid` column to the non-numeric dataframe in order to see its correlations with the non-numeric predictors.

<details>
<summary>**Hints**</summary>
```{r, eval=FALSE}
houses_tidy_numeric <- houses_tidy %>%
  select_if(is.numeric)

houses_tidy_nonnumeric <- houses_tidy %>%
  select_if(function(x) !is.numeric(x))

houses_tidy_nonnumeric$price <- houses_tidy$price

ggpairs(houses_tidy_numeric)
ggpairs(houses_tidy_nonnumeric)
```
and the same in subsequent rounds of predictor selection with the `resid` column.<br><br>
Remember, if you are not sure whether including a categorical predictor is statistically justified, run an `anova()` test passing in the models with- and without the categorical predictor and check the p-value of the test.
</details>

```{r}
ggpairs(houses_tidy_numeric, columns = c(1,2,3,4))
```
Correlation of sqft_above with price looks pretty promising, but split of price by grade and waterfront also look decent.

```{r}
houses_tidy %>%
  ggplot(aes(x = grade, y = price)) +
  geom_boxplot()
```

```{r}
mod1a <- lm(price ~ sqft_above, data = houses_tidy)
summary(mod1a)
```

```{r}
mod1b <- lm(price ~ grade, data = houses_tidy)
summary(mod1b)
# we can't drop some of the categorical data, so we keep all or drop all of the grades
```
```{r}
mod1c <- lm(price ~ waterfront, data = houses_tidy)
summary(mod1c)
```
```{r}
nullmodel <- lm(price ~ 1, data = houses_tidy)
grade_model <- lm(price ~ grade, data = houses_tidy)
anova(nullmodel, grade_model)
# the output tells us we should include all the categories of grades, as the grade model is statistically significant
```

```{r}
par(mfor = c(2,2))
plot(mod1b)
# we should actually reject the model given this output, but for the example we will continue anyway
```

```{r}
houses_resid <- houses_tidy %>% 
  add_residuals(mod1b) %>% 
  select(-c("price", "grade"))

houses_resid_numeric <- houses_resid %>% 
  select_if(is.numeric)

houses_resid_nonnumeric <- houses_resid %>% 
  select_if(function(x) !is.numeric(x))

houses_resid_nonnumeric$resid <- houses_resid$resid
```

```{r}
ggpairs(houses_resid_numeric)
```
```{r}
mod2a <- lm(price ~ grade + lat, data = houses_tidy)
summary(mod2a)
```

```{r}
ggpairs(houses_resid_nonnumeric)
# waterfront has the greatest variabilty in residuals, so we'll use that next
```

```{r}
mod2b <- lm(price ~ grade + waterfront, data = houses_tidy)
summary(mod2b)
```

```{r}
mod3a <- lm(price ~ grade + lat)
# we just "rinse and repeat" the process until we select the best 
```

# Extensions

* Consider possible interactions between your four main effect predictors and test their effect upon $r^2$. Choose your best candidate interaction and visualise its effect. 

* Calculate the relative importance of predictors from your best $4$-predictor model (i.e. the model without an interaction). Which predictor affects `price` most strongly?

